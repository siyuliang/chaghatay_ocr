{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59090fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install relevant packages\n",
    "# !pip install kraken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f4cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2;36m[04/16/25 14:19:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m No metadata found for record            \u001b]8;id=526110;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py\u001b\\\u001b[2mrepo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=994427;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'10.5281/zenodo.15030337'\u001b[0m.              \u001b[2m           \u001b[0m\n",
      "\u001b[2K\u001b[2;36m[04/16/25 14:19:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m No metadata found for record            \u001b]8;id=528788;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py\u001b\\\u001b[2mrepo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=673698;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'10.5281/zenodo.13862096'\u001b[0m.              \u001b[2m           \u001b[0m\n",
      "\u001b[2K\u001b[2;36m[04/16/25 14:19:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m No metadata found for record            \u001b]8;id=292619;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py\u001b\\\u001b[2mrepo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=818305;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'10.5281/zenodo.10599911'\u001b[0m.              \u001b[2m           \u001b[0m\n",
      "\u001b[2K\u001b[2;36m[04/16/25 14:19:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m No metadata found for record            \u001b]8;id=560528;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py\u001b\\\u001b[2mrepo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=440899;file:///Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/repo.py#264\u001b\\\u001b[2m264\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[32m'10.5281/zenodo.10259287'\u001b[0m.              \u001b[2m           \u001b[0m\n",
      "\u001b[2KRetrieving model list \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[35m 60%\u001b[0m \u001b[35m28/47\u001b[0m \u001b[36m0:00:11\u001b[0m \u001b[33m0:00:18\u001b[0m\n",
      "\u001b[?25h10.5281/zenodo.13942714 (pytorch) - Kuzushiji\u001b[0m\n",
      "10.5281/zenodo.13814200 (pytorch) - Segmentation model for historical Samaritan Manuscripts for one column pages, model trained on 13 pentateuchal Samaritan manuscripts\u001b[0m\n",
      "10.5281/zenodo.13788177 (pytorch) - McCATMuS - Transcription model for handwritten, printed and typewritten documents from the 16th century to the 21st century\u001b[0m\n",
      "10.5281/zenodo.13741957 (pytorch) - Model trained on 11th century manuscripts to produce graphematic transcription (Latin).\u001b[0m\n",
      "10.5281/zenodo.13736584 (pytorch) - Model trained on 11th century manuscripts to produce expanded transcription (Latin).\u001b[0m\n",
      "10.5281/zenodo.11113737 (pytorch) - Latin Incunabula and Early Prints\u001b[0m\n",
      "10.5281/zenodo.10886224 (pytorch) - Model train on openly licensed data from HTR-United from the 17th century to the 21st were used.\u001b[0m\n",
      "10.5281/zenodo.10602357 (pytorch) - CATMuS-Print (Tiny, 2024-01-31) - Diachronic model for French prints and other languages\u001b[0m\n",
      "10.5281/zenodo.10592716 (pytorch) - CATMuS-Print (Large, 2024-01-30) - Diachronic model for French prints and other languages\u001b[0m\n",
      "10.5281/zenodo.10519596 (pytorch) - OCR model for German prints trained from several datasets\u001b[0m\n",
      "10.5281/zenodo.8425684 (pytorch) - Experimental printed syriac model\u001b[0m\n",
      "10.5281/zenodo.8193498 (pytorch) - Transcription model for Lucien Peraire's handwriting (French, 20th century)\u001b[0m\n",
      "10.5281/zenodo.7933463 (pytorch) - HTR model for German manuscripts trained from several datasets\u001b[0m\n",
      "10.5281/zenodo.7933402 (pytorch) - Fraktur model trained from enhanced Austrian Newspapers dataset\u001b[0m\n",
      "10.5281/zenodo.7631619 (pytorch) - Model trained on all available data, from 8th to 16th century, from GalliCorpora, CREMMA Medieval and CREMMA Medieval Lat, as well as data from Eutyches, Caroline Minuscule, DecameronFR. Transcription guidelines: https://hal.archives-ouvertes.fr/hal-03697382\u001b[0m\n",
      "10.5281/zenodo.7410529 (pytorch) - Gallicorpora+ ancient prints (Litterature)\u001b[0m\n",
      "10.5281/zenodo.7051644 (pytorch) - Printed Persian Base Model Trained on the OpenITI Corpus\u001b[0m\n",
      "10.5281/zenodo.7050342 (pytorch) - Printed Ottoman Base Model Trained on the OpenITI Corpus\u001b[0m\n",
      "10.5281/zenodo.7050296 (pytorch) - Printed Arabic Base Model Trained on the OpenITI Corpus\u001b[0m\n",
      "10.5281/zenodo.7050270 (pytorch) - Printed Arabic-Script Base Model Trained on the OpenITI Corpus\u001b[0m\n",
      "10.5281/zenodo.6669508 (pytorch) - Cremma-Medieval Old French Model (Litterature)\u001b[0m\n",
      "10.5281/zenodo.6542744 (pytorch) - LECTAUREP Contemporary French Model (Administration)\u001b[0m\n",
      "10.5281/zenodo.5468665 (pytorch) - Medieval Hebrew manuscripts in Sephardi bookhand version 1.0\u001b[0m\n",
      "10.5281/zenodo.5468573 (pytorch) - Medieval Hebrew manuscripts in Italian bookhand version 1.0\u001b[0m\n",
      "10.5281/zenodo.5468478 (pytorch) - Medieval Hebrew manuscripts in Ashkenazi bookhand\u001b[0m\n",
      "10.5281/zenodo.5468286 (pytorch) - Medieval Hebrew manuscripts version 1.0\u001b[0m\n",
      "10.5281/zenodo.2577813 (pytorch) - A generalized model for English printed text\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kraken list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f41782d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 10.5281/zenodo.7050270\n",
      "\n",
      "Printed Arabic-Script Base Model Trained on the OpenITI Corpus\n",
      "\n",
      "Printed Arabic-Script Base Model Trained on the OpenITI Corpus\n",
      "==============================================================\n",
      "\n",
      "This is a text recognition model trained on the OpenITI dataset of printed\n",
      "Arabic-script text available at [0] in its state of 2022-09-03. It encompasses\n",
      "real world Arabic (~23k lines), Persian (~17k lines), Urdu (~11k lines), and\n",
      "Ottoman Turkish (~7100 lines) material in a variety of typefaces augmented by a\n",
      "synthetic data in the Tahoma (600 lines) typeface.\n",
      "\n",
      "As the model is trained on a variety of languages and highly diverse typefaces\n",
      "it is mostly intended as a base model for fine-tuning more specific models from\n",
      "it. In line with this it has not been extensively verified or optimized.\n",
      "\n",
      "The ground truth was lightly normalized to NFD but is otherwise untouched. \n",
      "\n",
      "[0]: https://github.com/OpenITI/arabic_print_data.git\n",
      "scripts: Arab\n",
      "alphabet: !\"'()*+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPRSTUVWX[\\]_abcdefghijklmnoprstuvwxyz{|}«»،؎؛؟ءابةتثجحخدذرزسشصضطظعغـفقكلمنهوىي٠١٢٣٤٥٦٧٨٩٪٭ٱٴٹپچڈڑژڤکڭگںھہۃیے۔ە۰۱۲۳۴۵۶۷۸۹ݣ‘’“”∗☆﴾﴿ﷲﷺﺅ SPACE, ARABIC SIGN SALLALLAHOU ALAYHE WASSALLAM, ARABIC SIGN ALAYHE ASSALLAM, ARABIC SIGN RAHMATULLAH ALAYHE, ARABIC SIGN RADI ALLAHOU ANHU, ARABIC SIGN TAKHALLUS, ARABIC FATHATAN, ARABIC DAMMATAN, ARABIC KASRATAN, ARABIC FATHA, ARABIC DAMMA, ARABIC KASRA, ARABIC SHADDA, ARABIC SUKUN, ARABIC MADDAH ABOVE, ARABIC HAMZA ABOVE, ARABIC HAMZA BELOW, ARABIC SUBSCRIPT ALEF, ARABIC INVERTED DAMMA, ARABIC LETTER SUPERSCRIPT ALEF, ARABIC SMALL HIGH THREE DOTS, RIGHT-TO-LEFT MARK\n",
      "accuracy: 95.31%\n",
      "license: cc-zero\n",
      "author(s): Benjamin Kiessling\n",
      "date: 2022-09-05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kraken show 10.5281/zenodo.7050270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:10\u001b[0m00:10\u001b[0m00:09\u001b[0m\n",
      "\u001b[?25hModel name: arabic_best.mlmodel\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download the model\n",
    "!kraken get 10.5281/zenodo.7050296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a462a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ANN /Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/blla.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN arabic_best.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Segmenting ../data/v1.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m16/16\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hWriting recognition results for ../data/v1.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Running on one sample image\n",
    "!kraken -i ../data/v1.jpg ../output/kraken_arabic_best.txt segment -bl ocr -m arabic_best.mlmodel --text-direction horizontal-tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a2f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/coremltools/models/model.py:561: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error: Error reading protobuf spec. validator error: Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).\".\n",
      "  _warnings.warn(\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/coremltools/models/model.py:561: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error: Error reading protobuf spec. validator error: Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).\".\n",
      "  _warnings.warn(\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/rpred.py:322: UserWarning: Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.\n",
      "  warnings.warn('Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → ../output/kraken_arabic_best.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from kraken import binarization, blla, pageseg, rpred\n",
    "from kraken.lib import models\n",
    "\n",
    "# ─── paths ────────────────────────────────────────────────────────────────\n",
    "img_path  = Path(\"../data/v1.jpg\")\n",
    "out_path  = Path(\"../output/kraken_arabic_best.txt\")\n",
    "rec_model = Path(\"/Users/siyuliang//Library/Application Support/kraken/all_arabic_scripts.mlmodel\")       # adjust if the file lives elsewhere\n",
    "\n",
    "# ─── 1. load the image ────────────────────────────────────────────────────\n",
    "im = Image.open(img_path)\n",
    "\n",
    "# ─── 2. segment the page ─────────────────────────────────────────────────\n",
    "# CLI flag  -bl  → baseline‑layout segmenter.  In the API that’s blla.segment.\n",
    "# Kraken ships a *default* segmentation model, so model=None is fine.\n",
    "# Valid text‑direction strings are \"horizontal-lr\" (L‑to‑R) or \"horizontal-rl\".\n",
    "seg = blla.segment(im, text_direction=\"horizontal-lr\")   # ← equivalent to -bl\n",
    "\n",
    "# (If you ever want the legacy bounding‑box segmenter instead of -bl, do:)\n",
    "# bw  = binarization.nlbin(im)          # binarize first\n",
    "# seg = pageseg.segment(bw, text_direction=\"horizontal-lr\")\n",
    "\n",
    "# ─── 3. load the Arabic recogniser ────────────────────────────────────────\n",
    "network = models.load_any(rec_model)\n",
    "\n",
    "# ─── 4. run OCR line‑by‑line and save it ──────────────────────────────────\n",
    "text_lines = [rec.prediction for rec in rpred.rpred(network, im, seg)]\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(\"\\n\".join(text_lines), encoding=\"utf‑8\")\n",
    "print(\"Done →\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/siyuliang/Library/Application Support/kraken/all_arabic_scripts.mlmodel\n",
      "/Users/siyuliang/Library/Application Support/kraken/arabic_best.mlmodel\n"
     ]
    }
   ],
   "source": [
    "# Checking what models you have\n",
    "# Need to be replaced with your own path\n",
    "from pathlib import Path\n",
    "\n",
    "# macOS default\n",
    "kraken_dir = Path.home() / \"Library/Application Support/kraken\"\n",
    "\n",
    "# Linux default would be:  Path.home() / \".local/share/kraken\"\n",
    "\n",
    "for p in kraken_dir.rglob(\"*.mlmodel\"):\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b4f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 specified images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/rpred.py:322: UserWarning: Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.\n",
      "  warnings.warn('Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.')\n",
      "Extracting line failed: Baseline length below minimum 5px\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/coremltools/models/model.py:561: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error: Error reading protobuf spec. validator error: Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).\".\n",
      "  _warnings.warn(\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/rpred.py:322: UserWarning: Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.\n",
      "  warnings.warn('Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.')\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/coremltools/models/model.py:561: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error: Error reading protobuf spec. validator error: Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).\".\n",
      "  _warnings.warn(\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/rpred.py:322: UserWarning: Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.\n",
      "  warnings.warn('Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.')\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/coremltools/models/model.py:561: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: \"compiler error: Error reading protobuf spec. validator error: Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).\".\n",
      "  _warnings.warn(\n",
      "/Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/rpred.py:322: UserWarning: Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.\n",
      "  warnings.warn('Using legacy polygon extractor, as the model was not trained with the new method. Please retrain your model to get speed improvement.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manuscript      lines  CER     WER   \n",
      "--------------------------------------------------------------\n",
      "Jarring_Prov_2     10  0.9644  7.6000\n",
      "Jarring_Prov_3      8  0.9109  7.1250\n",
      "Jarring_Prov_4      9  0.8814  7.7778\n",
      "Jarring_Prov_5      9  0.9256  7.8889\n",
      "ALL                36  0.9222  7.6111\n",
      "\n",
      "✓ Results:   output/kraken_eval.tsv\n",
      "✓ OCR txts:  Jarring_Prov_2_004_r.Lanczos.800.65_4a.ocr.txt, Jarring_Prov_3_fol_003_r.Lanczos.800.65_3a.ocr.txt, Jarring_Prov_4_002_v.Lanczos.800.65_2b.ocr.txt, Jarring_Prov_5_003_r.Lanczos.800.65_3a.ocr.txt\n",
      "✓ GT txts:   Jarring_Prov_2_004_r.Lanczos.800.65_4a.gt.txt, Jarring_Prov_3_fol_003_r.Lanczos.800.65_3a.gt.txt, Jarring_Prov_4_002_v.Lanczos.800.65_2b.gt.txt, Jarring_Prov_5_003_r.Lanczos.800.65_3a.gt.txt\n"
     ]
    }
   ],
   "source": [
    "# Full code to evaluate the Kraken Arabic model on a list of manuscript pages\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Evaluate the Kraken Arabic model on a list of manuscript pages,\n",
    "save a TSV with CER/WER *and* write both the raw OCR output\n",
    "and ground truth as .txt files.\n",
    "\n",
    "Run from project root or from src/:\n",
    "    $ python src/eval_kraken.py\n",
    "\"\"\"\n",
    "\n",
    "import json, random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "from kraken import blla, rpred\n",
    "from kraken.lib import models\n",
    "\n",
    "# ─── locate project root ──────────────────────────────────────────────────\n",
    "try:                                   # running as script\n",
    "    ROOT_DIR = Path(__file__).resolve().parent.parent   # …/ocr\n",
    "except NameError:                      # running in notebook\n",
    "    cwd = Path.cwd().resolve()\n",
    "    ROOT_DIR = cwd if (cwd / \"data\").exists() else cwd.parent\n",
    "\n",
    "# ─── PATHS & CONFIG ───────────────────────────────────────────────────────\n",
    "JSON_PATH = ROOT_DIR / \"data/jarring_manuscripts_data/jarring_manuscripts_structured.json\"\n",
    "IMG_ROOT  = ROOT_DIR / \"data/jarring_manuscripts_data\"          # prefix to local_image_path\n",
    "OUT_DIR   = ROOT_DIR / \"output\"                                 # existing output folder\n",
    "OUT_TSV   = OUT_DIR  / \"kraken_eval.tsv\"\n",
    "\n",
    "REC_MODEL_PATH = Path.home() / \"Library/Application Support/kraken/arabic_best.mlmodel\"\n",
    "TEXT_DIRECTION = \"horizontal-rl\"\n",
    "SEED           = 42\n",
    "\n",
    "# ═════════════════════════════════════════════════════════════════════════\n",
    "# CONFIGURATION OPTIONS - Modify these to control which images to process\n",
    "# ═════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Option 1: Use specific image paths (set to empty list to use PROCESS_ALL_IMAGES)\n",
    "ALLOWED_IMAGES = [\n",
    "    \"images/Jarring_Prov_2/Jarring_Prov_2_004_r.Lanczos.800.65_4a.jpg\",\n",
    "    \"images/Jarring_Prov_3/Jarring_Prov_3_fol_003_r.Lanczos.800.65_3a.jpg\",\n",
    "    \"images/Jarring_Prov_4/Jarring_Prov_4_002_v.Lanczos.800.65_2b.jpg\",\n",
    "    \"images/Jarring_Prov_5/Jarring_Prov_5_003_r.Lanczos.800.65_3a.jpg\",\n",
    "]\n",
    "\n",
    "# Option 2: Process all images in JSON (set to True to override ALLOWED_IMAGES)\n",
    "PROCESS_ALL_IMAGES = False\n",
    "\n",
    "# ─── METRIC HELPERS ───────────────────────────────────────────────────────\n",
    "def _lev(a, b):\n",
    "    if len(a) < len(b):\n",
    "        a, b = b, a\n",
    "    prev = list(range(len(b) + 1))\n",
    "    for i, ca in enumerate(a, 1):\n",
    "        cur = [i]\n",
    "        for j, cb in enumerate(b, 1):\n",
    "            cur.append(min(cur[j-1] + 1,\n",
    "                           prev[j]  + 1,\n",
    "                           prev[j-1] + (ca != cb)))\n",
    "        prev = cur\n",
    "    return prev[-1]\n",
    "\n",
    "def cer(ref, hyp):\n",
    "    return 0.0 if not ref else _lev(ref.strip(), hyp.strip()) / len(ref)\n",
    "\n",
    "def wer(ref, hyp):\n",
    "    ref_t, hyp_t = ref.split(), hyp.split()\n",
    "    return 0.0 if not ref_t else _lev(ref_t, hyp_t) / len(ref_t)\n",
    "\n",
    "# ─── MAIN ─────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # 1 ▸ load JSON\n",
    "    with open(JSON_PATH, encoding=\"utf-8\") as f:\n",
    "        all_recs = json.load(f)\n",
    "\n",
    "    # 2 ▸ filter records based on configuration\n",
    "    if PROCESS_ALL_IMAGES:\n",
    "        recs = all_recs\n",
    "        print(f\"Processing all {len(recs)} images from JSON\")\n",
    "    else:\n",
    "        # Convert to set for faster lookups\n",
    "        allowed_set = set(ALLOWED_IMAGES)\n",
    "        recs = [r for r in all_recs if r[\"local_image_path\"] in allowed_set]\n",
    "        print(f\"Processing {len(recs)} specified images\")\n",
    "    \n",
    "    if not recs:\n",
    "        raise RuntimeError(\"No specified images found in JSON.\")\n",
    "\n",
    "    # 3 ▸ bundle by manuscript for later aggregation\n",
    "    by_ms = defaultdict(list)\n",
    "    for r in recs:\n",
    "        by_ms[r[\"manuscript_id\"]].append(r)\n",
    "\n",
    "    # 4 ▸ load recogniser\n",
    "    network = models.load_any(REC_MODEL_PATH)\n",
    "\n",
    "    # 5 ▸ OCR + metrics\n",
    "    stats = defaultdict(lambda: Counter(lines=0, char_err=0, word_err=0))\n",
    "\n",
    "    for rec in recs:\n",
    "        ms_id      = rec[\"manuscript_id\"]\n",
    "        img_path   = IMG_ROOT / rec[\"local_image_path\"]\n",
    "        image      = Image.open(img_path)\n",
    "        segments   = blla.segment(image, text_direction=TEXT_DIRECTION)\n",
    "        preds      = [l.prediction for l in rpred.rpred(network, image, segments)]\n",
    "        gold_lines = [ln[\"arabic_text\"] for ln in rec[\"lines\"]]\n",
    "\n",
    "        # Create base filename for outputs\n",
    "        base_filename = Path(rec[\"local_image_path\"]).with_suffix(\"\").name\n",
    "        \n",
    "        # save OCR text ----------------------------------------------------\n",
    "        ocr_txt_path = OUT_DIR / f\"{base_filename}.ocr.txt\"\n",
    "        ocr_txt_path.write_text(\"\\n\".join(preds), encoding=\"utf-8\")\n",
    "        \n",
    "        # save ground truth text -------------------------------------------\n",
    "        gt_txt_path = OUT_DIR / f\"{base_filename}.gt.txt\"\n",
    "        gt_txt_path.write_text(\"\\n\".join(gold_lines), encoding=\"utf-8\")\n",
    "\n",
    "        # metrics ----------------------------------------------------------\n",
    "        for ref, hyp in zip(gold_lines, preds):\n",
    "            stats[ms_id][\"lines\"]    += 1\n",
    "            stats[ms_id][\"char_err\"] += cer(ref, hyp) * len(ref)\n",
    "            stats[ms_id][\"word_err\"] += wer(ref, hyp) * len(ref.split())\n",
    "\n",
    "    # 6 ▸ aggregate & print/save table\n",
    "    header = [\"manuscript\", \"lines\", \"CER\", \"WER\"]\n",
    "    rows, total = [], Counter(lines=0, char_err=0, word_err=0)\n",
    "\n",
    "    for ms_id, c in sorted(stats.items()):\n",
    "        tot_chars_ms = sum(len(l[\"arabic_text\"])\n",
    "                           for r in recs if r[\"manuscript_id\"] == ms_id\n",
    "                           for l in r[\"lines\"])\n",
    "        rows.append((ms_id, c[\"lines\"],\n",
    "                     f\"{c['char_err']/tot_chars_ms:.4f}\",\n",
    "                     f\"{c['word_err']/c['lines']:.4f}\"))\n",
    "        total.update(c)\n",
    "\n",
    "    tot_chars_all = sum(len(l[\"arabic_text\"]) for r in recs for l in r[\"lines\"])\n",
    "    rows.append((\"ALL\", total[\"lines\"],\n",
    "                 f\"{total['char_err']/tot_chars_all:.4f}\",\n",
    "                 f\"{total['word_err']/total['lines']:.4f}\"))\n",
    "\n",
    "    w = [max(len(str(r[i])) for r in ([header] + rows)) for i in range(4)]\n",
    "    fmt = \"  \".join(f\"{{:{k}}}\" for k in w)\n",
    "\n",
    "    print(fmt.format(*header))\n",
    "    print(\"-\"*sum(w)*2)\n",
    "    for r in rows:\n",
    "        print(fmt.format(*r))\n",
    "\n",
    "    # TSV\n",
    "    with OUT_TSV.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\t\".join(header) + \"\\n\")\n",
    "        for r in rows:\n",
    "            f.write(\"\\t\".join(map(str, r)) + \"\\n\")\n",
    "    print(\"\\n✓ Results:  \", OUT_TSV.relative_to(ROOT_DIR))\n",
    "    print(\"✓ OCR txts: \", \", \".join(sorted(p.name for p in OUT_DIR.glob(\"*.ocr.txt\"))))\n",
    "    print(\"✓ GT txts:  \", \", \".join(sorted(p.name for p in OUT_DIR.glob(\"*.gt.txt\"))))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fd2744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:08\u001b[0mm \u001b[33m0:00:08\u001b[0m\n",
      "\u001b[?25hModel name: all_arabic_scripts.mlmodel\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kraken get 10.5281/zenodo.7050270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ANN /Users/siyuliang/anaconda3/lib/python3.11/site-packages/kraken/blla.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Loading ANN all_arabic_scripts.mlmodel\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "Segmenting v1.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n",
      "\u001b[2KProcessing \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[35m16/16\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hWriting recognition results for v1.jpg\t\u001b[0m\u001b[32m✓\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kraken -i ../data/v1.jpg ../output/kraken_all_ara.txt segment -bl ocr -m all_arabic_scripts.mlmodel --text-direction horizontal-tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
